close all;
clc;
clear all;
px(1)=input('Enter probability of x1');
px(2)=1-px(1);
py=[0 0];
p=input('Enter conditional probability P(y1/x1)=p= ');
pygx=[p 1-p;1-p p]
for i=1:2
for j=1:2
pxy(i,j)=(px(i)*pygx(i,j));
end
end
py=[0 0];
for i=1:2
for j=1:2
py(i)=py(i)+pxy(j,i);
end
end
hx=0;
for i=1:2
h=px(i)*(log(1/px(i))/log(2))
hx=hx+h;
end
hy=0;
for i=1:2
y=py(i)*(log(1/py(i))/log(2));
hy=hy+y;
end
Hxy=0;
for i=1:2
for j=1:2
if pxy(i,j)==0
hxy=0;
else
hxy=-pxy(i,j)*log2(pxy(i,j));
Hxy=Hxy+hxy;
end
end
end
Hygx=Hxy-hx;
Ixy=hy-Hygx;
Hxgy=Hxy-hy;
if pygx(1,1)~=1
c=1+[p*log2(p)+(1-p)*log2(1-p)]
elseif p==1
c=log2(2);
end
z=['Input probabilities are= ',num2str(px)];
disp(z)
disp('Channel conditional probability matrix is= ');
pygx
disp('Channel joint probability matrix is= ');
pxy
z=['Output probabiilties are= ',num2str(py)];
disp(z)
z=['Entropy of source H(X)= ',num2str(hx),'bits/msg'];
disp(z)

z=['Entropy of source H(Y)= ',num2str(hy),'bits/msg'];
disp(z)
z=['Conditional entropy H(Y/X)= ',num2str(Hygx),'bits/msg'];
disp(z)
z=['Joint entropy Hxy= ',num2str(Hxy),'bits/msg'];
disp(z)
z=['Conditional probability H(X/Y)= ',num2str(Hxgy),'bits/msg']
disp(z)
z=['Mutual information Ixy= ',num2str(Ixy),'bits'];
disp(z)
z=['Channel capacity C is= ',num2str(c),'bits/sec'];
disp(z)
